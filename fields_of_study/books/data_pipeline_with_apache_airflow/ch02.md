# Chapter 02. Airflow DAG의 구조

### Airflow DAG 작성 예제
<img width="672" alt="image" src="https://github.com/dhkdn9192/data_engineer_career/assets/11307388/005f9f45-c369-4b0a-a396-5717b8b53aaf">


```python
dag = DAG(
    dag_id="download_rocket_launches",
    description="Download rocket pictures of recently launched rockets.",
    start_date=airflow.utils.dates.days_ago(14),
    schedule_interval="@daily",
)

download_launches = BashOperator(
    task_id="download_launches",
    bash_command="curl -o /tmp/launches.json -L 'https://ll.thespacedevs.com/2.0.0/launch/upcoming'",  # noqa: E501
    dag=dag,
)

def _get_pictures():
    # Ensure directory exists
    pathlib.Path("/tmp/images").mkdir(parents=True, exist_ok=True)

    # Download all pictures in launches.json
    with open("/tmp/launches.json") as f:
        launches = json.load(f)
        image_urls = [launch["image"] for launch in launches["results"]]
        for image_url in image_urls:
            try:
                response = requests.get(image_url)
                image_filename = image_url.split("/")[-1]
                target_file = f"/tmp/images/{image_filename}"
                with open(target_file, "wb") as f:
                    f.write(response.content)
                print(f"Downloaded {image_url} to {target_file}")
            except requests_exceptions.MissingSchema:
                print(f"{image_url} appears to be an invalid URL.")
            except requests_exceptions.ConnectionError:
                print(f"Could not connect to {image_url}.")

get_pictures = PythonOperator(
    task_id="get_pictures", python_callable=_get_pictures, dag=dag
)

notify = BashOperator(
    task_id="notify",
    bash_command='echo "There are now $(ls /tmp/images/ | wc -l) images."',
    dag=dag,
)

download_launches >> get_pictures >> notify
```

### 태스크 실행 순서 정의
```
download_launches >> get_pictures >> notify
```
- Airflow에선 **오른쪽 시프트 연산자** (binary right shift operator), 즉 "rshift"(>>)를 사용하여 태스크 간 의존성을 정의한다.
- 파이썬에서 rshift 연산자는 비트를 이동하는데 사용된다.
- 그러나 Airflow에선 비트연산자를 사용할 일이 없으므로 위와 같은 용도로 재정의하여 사용하고 있다.

### 태스크와 오퍼레이터의 차이점
- 오퍼레이터는 **단일 작업 수행 역할**을 한다.
- 교재 및 Airflow 공식문서에선 오퍼레이터와 태스크라는 용어를 **같은 의미로 사용**한다. (사용자 관점에선 모두 같은 의미)
- 하지만 두 용어에는 차이점이 존재한다.
  - **오퍼레이터**: Airflow 사용자가 이용하는 다양한 서브 클래스 (PythonOperator, EmailOperator 등)
  - **태스크**: 오퍼레이터의 상태를 관리하는 Airflow의 내장 컴포넌트
- DAG는 이러한 오퍼레이터 집합의 수행을 오케스트레이션한다.
<img width="570" alt="image" src="https://github.com/dhkdn9192/data_engineer_career/assets/11307388/3c5187b7-4f2c-46ab-8f40-d33397f6fd2a">

