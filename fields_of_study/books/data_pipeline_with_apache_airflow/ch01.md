# Chapter 01. Apache Airflow 살펴보기


## 1.1 데이터 파이프라인 소개

### 방향성 비순환 그래프(Directed Acyclic Graph, DAG)
- 파이프라인을 그래프로 표현하면 태스크 간 의존성을 나타낼 수 있다.
- 태스크는 노드로, 의존성은 노드 간의 방향으로 표시한다.
- 그래프는 반복이나 순환을 허용하지 않는다. -> 교착상태(deadlock)을 막기 위한 중요한 성질

### 그래프 파이프라인이 절차적 스크립트 파이프라인보다 나은 이유
- 파이프라인을 작은 태스크들로 병확하게 분리할 수 있다.
- 더 효율적인 컴퓨팅 리소스 사용 (태스크 병렬 실행 등)
- 중간에 실패가 발생하면 실패한 태스크만 재실행하면 된다.
  - 모놀리식(monolithic) 스크립트 또는 프로세스는 중간 태스크 실패 시, 전체 스크립트를 재실행해야 하므로 비효율적이다.

### 워크플로 매니저 비교
- 공통점: 의존성 있는 다수의 태스크가 포함된 파이프라인을 정의하고 실행하는 기능 제공
- 차이점1: 워크플로 정의 방식
  - (Oozie 등) XML 정적 파일로 정의 -> 읽기 쉽지만 유연하지 않음
  - (Luigi, Airflow 등) 코드로 정의 -> 읽기 어렵지만 유연함
- 차이점2: 워크플로 관리자가 제공하는 기능의 범위
  - (Make, Luigi 등) 워크플로 스케줄을 위한 기본 기능을 제공하지 않음 -> Cron 등 추가 도구 필요
- 결론: Airflow는 데이터 지향적인 워크플로와 파이프라인 처리에 적합함
<img width="744" alt="image" src="https://github.com/dhkdn9192/data_engineer_career/assets/11307388/ebeac594-1f73-4d44-b5e3-504cce771843">


## 1.2 Airflow 소개

### 파이프라인 스케줄링 및 실행
- Python 프로그래밍 접근 방식이 DAG를 구성하는데 많은 **유연성**을 제공한다.
- Airflow로 **여러 시스템 간에 데이터 프로세스를 결합**할 수 있다.
- Airflow의 세 가지 구성요소
  - **스케줄러**: DAG를 분석하고 워커에 DAG의 태스크를 예약한다.
  - **워커**: 예약된 태스크를 실행한다.
  - **웹 서버**: DAG 시각화 및 실행 결과 확인한다.
- Airflow가 DAG를 실행하는 과정
<img width="758" alt="image" src="https://github.com/dhkdn9192/data_engineer_career/assets/11307388/c58031b7-b875-4232-a169-2f41796501bf">

### Airflow를 선택하는 이유
* **파이썬** 언어에서 구현 가능한 방법들로 복잡한 파이프라인을 만들 수 있다.
* 쉽게 **확장** 가능하고 다양한 시스템과 **통합**할 수 있다.
* 전체 파이프라인을 재실행할 필요 없는 효율적인 파이프라인을 구축할 수 있다.
* **백필** 기능을 사용하면 과거 데이터를 손쉽게 재처리할 수 있다.
* 특정 벤더에 종속되지 않는 **오픈 소스**이다.

### Airflow가 적합하지 않은 경우
* Airflow는 배치 처리에 초점을 두므로 **스트리밍 처리에 적합하지 않다**.
* Airflow는 실행되는 동안 구조가 변경되는 **동적 파이프라인에 적합하지 않다**.
* 파이썬 프로그래밍 경험이 없는 경우 적합하지 않을 수 있다.
* 장기적으로 Airflow DAG를 유지 관리하기 위해서는 **초기 사용 시점부터 엄격한 관리가 필요**하다.
* Airflow는 데이터 계보 관리, 데이터 버전 관리와 같은 확장 기능을 제공하지 않는다.

