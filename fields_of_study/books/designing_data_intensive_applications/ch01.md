# 01장 - 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션

## 데이터 시스템에 대한 생각

- 데이터베이스, 큐, 캐시 등을 왜 서로 다른 범주임에도 데이터 시스템이라는 포괄적 용어로 묶어야 할까?
    - 데이터 저장과 처리를 위해 최근에 만들어진 도구들은 **분류 간 경계가 흐려짐**
        - 데이터스토어인 Redis를 메시지 큐로 사용하거나
        - 메시지 큐인 Kafka를 데이터베이스처럼 사용하는 등
    - 점점 더 많은 애플리케이션이 단일 도구로는 더 이상 데이터 처리와 저장 모두를 만족시킬 수 없는 과도하고 광범위한 요구사항을 가짐
- 대부분의 소프트웨어 시스템에서 중요하게 여기는 세 가지 관심사

| 항목 | 내용 |
| --- | --- |
| 신뢰성(Reliablility) | H/W, S/W 결함이나 human error에 직명하더라도 시스템이 지속적으로 올바르게 동작해야 한다. |
| 확장성(Scalability) | 시스템의 데이터 양, 트래픽 양, 복잡도가 증가하면 이를 처리할 적절한 방법이 있어야 한다. |
| 유지보수성(Maintainability) | 시간이 지나도 여러 다양한 사람들이 시스템 상에서 생산적으로 작업할 수 있어야 한다. |

## 신뢰성

- 소프트웨어에서 신뢰성이란 “시스템이 올바르게 동작”하며, 대략 “무엇인가 잘못되더라도 지속적으로 올바르게 동작함”을 의미한다.
- 잘못될 수 있는 일을 **결함(fault)** 라 부른다.
- 결함을 예측하고 대응할 수 있는 시스템을 **내결함성(fault-tolerant)** 또는 **탄력성(resilient)** 을 지녔다고 말한다.
- 결함과 **장애(failure)** 는 동일하지 않다.
    - 결함은 사양을 벗어난 시스템의 한 구성요소이지만
    - 장애는 사용자에게 필요한 서비스를 제공하지 못 하고 시스템 전체가 멈춘 경우를 의미

### 하드웨어 결함

- 하드디스크나 램 등 하드웨어의 결함, 대규모 정전, 네트워크 단절 등
- 큰 규모의 데이터센터, 클러스터 등 하드웨어 장비가 많아질 수록 하드웨어 결함이 발생하는 빈도 또한 늘 수 밖에 없다.
- 시스템 장애율을 줄이기 위해 하드웨어 구성 요소에 **중복(redundancy)** 을 추가할 수 있다.
    - 디스크를 RAID로 구성
    - 그 밖에는 서버 이중 전원 디바이스, 핫스왑 가능한 CPU, 데이터센터 예비 발전기 등
- 과거엔 단일장비의 전체 장애가 드물었으므로 하드웨어 구성 요소의 중복(reduntancy)로 충분했다.
- 그러나 오늘날에는 데이터양 증가와 소프트웨어의 계산 요구가 늘어남에 따라 **장비가 늘어나고 하드웨어 결함율 또한 늘어나는 추세**이다.
    - AWS 등 클라우드 플랫폼은 가상장비 인스턴스가 예고 없이 다운되는 경우가 상당히 일반적이다.
    - 단일장비의 신뢰성보다 **유연성(flexibility)** 과 **탄력성(elasticity)** 을 우선시하여 설계되었기 때문
- 따라서 **소프트웨어 내결함성 기술**을 사용하거나 **하드웨어 중복성을 추가**해 전체장비의 손실을 견딜 수 있는 시스템으로 점점 옮겨가고 있다.
    - 단일 서버 시스템은 재부팅이 필요한 경우, 서비스가 중단되므로 계획단 중단시간이 필요하지만
    - 위같은 경우, 전체 시스템의 중단시간 없이 한 번에 한 노드씩 재부팅(rolling restart)할 수 있다는 장점이 있다.

### 소프트웨어 오류

- 하드웨어 결함은 보통 무작위적이고 서로 독립적(디스크 하나 깨졌다고 옆 디스크도 깨지지는 않음)이거나 있더라도 약한 상관관계(서버실 온도같은 공통 원인)를 갖는다.
- 반면, **시스템 내 체계적 오류(systematic error)** 는 예상하기 어렵고, 노드간 상관관계 때문에 연쇄적으로 결함이 발생할 수도 있다.
- 이 같은 소프트웨어 결함을 유발하는 버그는 특정 상황에 의해 발생하기 전까진 오랫동안 나타나지 않는다.
- 소프트웨어의 체계적 오류는 신속하게 해결하기 어렵다. 할 수 있는 것은 아래 정도이다.
    - 시스템의 가정과 상호작용을 신중하게 생각하기
    - 빈틈없는 테스트
    - 프로세스 격리(process isolation)
    - 죽은 프로세스의 재시작 허용
    - 프로덕션 환경에서 시스템 동작의 측정 및 모니터링 등

### 인적 오류

- 대규모 인터넷 서비스에 대한 연구에 따르면 하드웨어 결함에 의한 중단은 10~25% 정도에 불과하고 대부분은 운영자의 설정 오류 때문이라고 한다.
- 인적 오류에 대해 신뢰성 있는 시스템을 갖추려면…
    - 오류 가능성을 최소화하는 방향으로 시스템을 설계 (잘 설계된 추상화, API, 인터페이스 등)
    - 인적 오류 가능성이 가장 높은 부분에서 사람의 실수로 장애가 발생할 수 있는 부분을 분리
    - 단위 테스트부터 전체 시스템 통합 테스트, 수동 테스트 등을 철저히 수행
    - 인적 오류가 발생했을 경우, 빠르게 복구하여 영향을 최소화할 수 있도록 조치 (설정 변경 내역을 빠르게 롤백하거나 새로운 코드를 서서히 롤아웃하도록 설계)
    - 성능 지표와 오류율같은 상세하고 명확한 모니터링 대책 마련
    - 조작 교육과 실습 수행

### 신뢰성은 얼마나 중요할까?

- 일반적으로 높은 신뢰성을 요구받는(원자력발전소, 항공교통관제) 분야 뿐만 아니라 일상적인 영역에서 사용되는 소프트웨어 역시 신뢰성이 중요하다
- 비즈니스 소프트웨어의 공식 수치가 오류로 나오는 버그 → 생산성 저하의 원인
- 전자 상거래 사이트의 중단 → 매출 손실
- 상대적으로 중요하지 않다고 여겨지는 소프트웨어 역시 신뢰성은 중요
    - 가족 사진들을 저장한 서비스에서 데이터가 영구적으로 유실되는 경우 등
- 서비스 운영 비용을 줄이기 위해 신뢰성을 희생해야하는 경우, 비용을 줄여야하는 시점을 매우 잘 알고 있어야 한다. (신중해야 한다)

## 확장성

- 확장성이 필요한 이유 : 현재 잘 동작한다고 해서 미래에도 안정적으로 동작한다는 보장이 없다.
- 성능 저하를 유발하는 흔한 이유 중 하나가 **부하 증가**이다.
- **확장성**이란 증가한 부하에 대처하는 시스템 능력을 설명하기 위한 용어이다.

### 부하 기술하기

- **부하 매개변수(load parameter)** : 시스템의 부하를 기술하기 위해 설정하는 파라미터
    - 웹 서버의 초당 요청 수, DB 읽기/쓰기 비율, 동시 활성 사용자 수, 캐시 적중률 등
- (트위터의 예시)
    - 트위터의 주요 두 가지 동작은 다음과 같다.
  
    | 동작 | 설명 |
    | --- | --- |
    | 트윗 작성 | 사용자는 팔로워에게 새로운 메시지를 게시할 수 있다. |
    | 홈 타임라인 | 사용자는 팔로우한 사람이 작성한 트윗을 볼 수 있다. |
    - 트위터의 이 두 동작을 구현할 땐 fan-out 문제를 겪게되며 아래 2가지 방법이 있다.
        - (1) “트윗 작성”은 새로운 트윗을 전역 컬렉션에 삽입하는 것으로 구현하고, 사용자가 “홈 타임라인”을 요청하면 다음과 같은 쿼리로 모든 팔로우하는 사람들과 그 사람들의 모든 트윗을 찾아 정렬하고 합친다.
        ![image](https://github.com/dhkdn9192/data_engineer_career/assets/11307388/3968bbb5-2083-4721-96b7-37c340ca75c8)

        ![image](https://github.com/dhkdn9192/data_engineer_career/assets/11307388/357972a6-bdf8-4fdc-93c5-4c066c9f270f)
        
        - (2) 각 사용자별 트윈 수신용 타임라인 캐시를 유지한다. 새로운 트윗이 작성되면 작성자를 팔로우하는 사람들을 모두 찾아 각 사용자의 타임라인 캐시에 새로운 트윗을 삽입한다. 이렇게 하면 “홈 타인라인”의 읽기 요청은 결과가 미리 계산되어 있으므로 비용이 저렴해진다.
        
        ![image](https://github.com/dhkdn9192/data_engineer_career/assets/11307388/906b6470-83e6-4a98-8a78-9159f337b7c0)

        
    - 트위터의 시스템은 “홈 타임라인” 질의 부하를 버텨내기 어려워 (1) → (2) 방식으로 전환했으며 현재는 두 가지 방식을 혼합한 하이브리드 방식을 사용한다. (팔로워가 너무 많은 유저는 1번 방식)

### 성능 기술하기

- 부하 매개변수를 설정했다면 이에 대한 성능 수치가 필요하다.
    - **처리량(throughput)** : 초당 처리할 수 있는 레코드 수, 혹은 작업 수행에 걸리는 전체 시간 → 하둡 등 일괄 처리 시스템에서 중요
    - **응답시간(response time)** : 클라이언트가 요청을 보내고 응답을 받기까지의 소요시간 → 온라인 시스템에서 중요
        - **지연시간(latency)** : 실제 처리시간, 네트워크 지연, 큐 지연 등을 모두 포함하는 응답시간과 달리, 서비스를 기다리며 휴지(latent) 상태인 시간을 말한다.
- 응답시간처럼 동일한 요청이더라도 매번 값이 다르게 나오는 지표는 단일 숫자가 아니라 측저 가능한 값의 **분포**로 나타내야 한다.
    - 일반적으로 평균보단 **중앙값(median)** 과 같은 **백분위(percentile)** 를 사용하는 편이 더 좋다. (outlier 등 이슈)
    - **꼬리 지연 시간(tail latency)** : 상위 백분위 응답 시간은 서비스 사용자의 경험에 직접 영향을 주기 때문에 중요하다. (99.9분위, 1000개 중 1개의 응답시간만이 과도하게 높아도 자주 이용하는 고객은 그 outlier 응답시간을 크게 체험)
- 성능 기술 시 백분위는 **서비스 수준 목표(service level objective, SLO)** 와 **서비스 수준 협약서(service level agreement, SLA)** 처럼 서비스 가용성을 정의하는 계약서에도 자주 등장한다.
    - e.g. “응답시간 중앙값이 200밀리초 미만이고 99분위가 1초 미만인 경우 정상 서비스로 간주한다.”

### 부하 대응 접근 방식

- 부하 매개변수와 지표 기술 방법을 바탕으로 다음과 같이 확장성을 고려할 수 있다.
    - **scaling up (vertical scaling)** : 보다 강력한 장비로 이동. 단일 고사양 장비는 매우 비싸다.
    - **scaling out (horizontal scaling)** : 다수의 낮은 사양의 장비에 부하를 분산 → **비공유(shared-nothing) 아키텍처**라고도 부른다.
- **탄력적(elastic)** 인 시스템 : 부하 증가를 감지하면 컴퓨팅 자원을 자동으로 추가
- 단일 노드에 stateful한 데이터 시스템을 분산 설치하는 것은 많은 복잡도를 요구함
    - 이런 이유로 고가용성 요구가 있을 때까지는 단일 노드에 데이터베이스를 유지하는 것이 최근까지의 통념이다.

## 유지보수성

- 소프트웨어 비용의 대부분은 초기 개발이 아니라 지속적인 유지보수에 들어간다.
    - 버그 수정, 시스템 운영 유지, 장애 조사, 새로운 플랫폼 적용 등
- 유지보수 비용을 줄이고 레거시 소프트웨어를 직접 만들지 않기 위한 소프트웨어 시스템 설계 원칙 3가지
    - **운용성(operatability)** : 운영팀이 시스템을 원활하게 운영할 수 있게 만들어라
    - **단순성(simplicity)** : 시스템의 복잡도를 최대한 제거해 새로운 엔지니어가 쉽게 이해하도록 만들어아
    - **발전성(evolvability)** : 엔지니어가 이후에 쉽게 변경할 수 있게 하라 
    

### 운용성: 운영의 편리함 만들기

> 좋은 운영으로 불완전한 소프트웨어의 제약을 피할 순 있지만, 나쁜 운영은 좋은 소프트웨어라도 작동을 신뢰할 수 없게 만든다.
- 운영 중 가능한 요소는 자동화하고 자동화된 작업이 제대로 동작하는지 확인하는 것이 중요
- 좋은 운영팀이 책임지는 작업
    - 시스템 상태 모니터링 및 빠르게 서비스를 복원
    - 시스템 장애, 성능 저하의 원인 추적
    - 보안 패치 등 플랫폼을 최신 상태로 유지
    - 시스템 간 영향을 확인해 문제가 생길 수 있는 변경사항을 손상 전에 차단
    - 용량 문제 등 미래에 발생할 문제를 예측해 사전에 해결
    - 배포, 설정 관리 등을 위한 모범 사례와 도구 마련
    - 개인 인사 이동에도 시스템에 대한 조직의 지식을 보존함 (인수인계 문서 잘 쓰라는?)
    

### 단순성: 복잡도 관리

- 복잡도 수렁에 빠진 소프트웨어 프로젝트를 때론 **커다란 진흙 덩어리(big ball of mud)** 라 부른다.
- 복잡도로 인한 다양한 증상
    - 모듈 간 강한 커플링(tight coupling)
    - 복잡한 의존성
    - 일관성 없는 명명(naming)과 용어
    - 임시방편으로 문제를 해결한 특수 사례 등
- 복잡도가 높아질 수록 소프트웨어 변경 시 버그 발생 위험이 커지는 등 유지보수가 어려워지므로 단순성을 고려하여 시스템을 구축해야 한다.
- **우발적 복잡도(accidental complexity)** : 사용자단에 대한 문제가 아니라 소프트웨어 구현에서만 발생하는 복잡도. 시스템을 단순하게 만드는 것은 단순히 기능을 줄이라는 것이 아니라, 우발적 복잡도를 줄이는 것을 포함한다.
- 우발적 복잡도를 제거하기 위한 최상의 도구는 **추상화**다.
    - 고수준 프로그래밍 언어는 기계어, CPU 레지스터, 시스템 호출을 숨긴 추상화
    - SQL은 디스크나 메모리에 존재하는 복잡한 데이터 구조, 다른 클라이언트의 동시 요청과 고장 후 불일치를 숨긴 추상화
    - 프로그래밍 언어의 추상화 덕분에 기계어 등 raw한 영역을 생각할 필요가 없어진다.
    

### 발전성: 변화를 쉽게 만들기

- 시스템의 요구사항은 끊임없이 변화할 가능성이 크다.
- 조직 프로세스 측면에서 애자일(agile) 작업 패턴은 변화에 적응하기 위한 프레임워크를 제공한다.
    - **테스트 주도 개발(test-driven development, TDD)** 과 **리팩토링(refactoring)** 같은 기술도구, 패턴 등
    

## 정리

- 애플리케이션을 신뢰할 수 있고 확장 가능하며 유지보수하기 쉽게 만들어주는 간단한 해결책은 없다.
