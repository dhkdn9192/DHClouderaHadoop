# 08장 - 분산 시스템의 골칫거리

앞서 다룬 이야기(복제 서버 장애 복구, 복제 지연, 트랜잭션의 동시성 제어 등)들도 8장에 비하면 낙관적이었다.

이제부턴 어떤 것이든 잘못될 가능성이 있담녀 잘못된다고 가정하고 다양한 케이스들을 다뤄본다.

## 결함과 부분 장애

- 하드웨어가 올바르게 동작하는 한 같은 연산은 항상 같은 결과를 낸다. → **결정적**이다.
- 일반적으로 컴퓨터는 **완전하게 동작**하거나 **전체 장애**가 발생한다. 그 중간 상태가 되지는 않는다.
    - 잘못된 결과는 다루기 어렵고 혼란스럽다.
- 그러나 분산 시스템에선 일부분은 잘 동작하지만 다른 부분은 예측할 수 없는 방식으로 고장날 수 있다. → **부분 장애(partial failure)** 또는 **비결정적**이다.
    - 심지어 뭔가 성공했는지 아닌지 알지 못할 수도 있다.
    - **비결정성**과 **부분 장애**는 분산 시스템을 다루기 어렵게 한다.

### 클라우드 컴퓨팅과 슈퍼컴퓨팅

- 대규모 컴퓨팅 시스템 구축 방법에 대한 몇 가지 철학
    - **고성능 컴퓨팅(high-performance computing, HPC)** :
        - 슈퍼컴퓨터. 일기예보 등 계산 비용이 높은 과학 계산 작업에 쓰인다.
        - 분산 시스템보다는 단일 노드 컴퓨터에 가깝다.
        - **부분 장애를 전체 장애로 확대**하는 방법으로 처리한다. (전체가 죽게 함)
    - **클라우드 컴퓨팅** :
        - 멀티 테넌트 데이터센터, 네트워크로 연결된 상용 컴퓨터, elastic/on-demand 자원 할당, 계량 결제(metered biling, aws처럼 사용한 만큼 컴퓨팅 비용 지불)와 관련됨
- 비교해볼 점
    - 서비스 중단 여부 (온라인 여부)
    - 상용 하드웨어 or 특화된 하드웨어
    - 데이터센터의 높은 대역폭을 위한 클로스 토폴로지(Clos topology) or HPC의 작업부하에서 높은 성능을 위해 특화된 네트워크 토폴로지
    - 수천 개의 노드로 구성된 시스템은 항상 뭔가 고장난 상태라고 가정하는게 합리적이다.
    - 시스템이 장애 노드를 감내할 수 있고, 전체적으로 계속 동작할 수 있다면 운영과 유지보수가 매우 유용하다. (순회식 업그레이드)
- 분산 시스템이 동작하게 하려면 **부분 장애 가능성**을 받아들이고, **소프트웨어에 내결함성 메커니즘을 넣어야** 한다.
- **신뢰성 없는 구성 요소를 사용해 신뢰성 있는 시스템을 구축해야 한다**.
    - error-correcting code는 일부 비트가 잘못될 수 있는 통신 채널에서 데이터를 정확히 전송시켜준다.
    - TCP는 패킷이 누락, 지연, 중복될 수 있는 IP 계층 위에서 더욱 신뢰성 높은 전송 계층을 제공해준다.

## 신뢰성 없는 네트워크

- 분산 시스템은 **비공유 시스템**
- 네트워크로 다수의 장비가 연결되며, 네트워크가 유일한 통신 수단이다.
- 비공유 시스템을 사용하는 이유
    - 특별한 하드웨어가 필요없어 상대적으로 저렴
    - 상품화된 클라우드 서비스 활용 가능
    - 여러 데이터센터에 중복 배치함으로써 높은 신뢰성 확보 가능
- **비동기 패킷 네트워크(asynchronous packet network)** :
    - 인터넷, IDC 내부 네트워크 대부분이 이에 해당
    - 네트워크는 메시지가 언제 도착할지 혹은 도착하기는 할 것인지 보장하지 않는다.
    - 요청과 응답 사이에 여러 가지가 잘못될 수 있다.
        - 요청이 손실됨
        - 요청이 큐 대기 후 나중에 전송됨
        - 원격 노드의 장애
        - 원격 노드가 일시적으로 멈췄다가 나중에 다시 응답하기 시작
        - 원격 노드가 요청을 처리했지만 응답이 손실됨
        - 원격 노드가 요청을 처리했지만 응답이 지연되다가 나중에 전송됨
    - 전송 측은 패킷이 전송됐는지 아닌지 조차도 구별할 수 없다.
    - 응답을 받지 못 했어도 그 이유를 아는 것이 불가능하다.
    - 이런 문제를 다루는 흔한 방법은 **타임아웃**이다.
    - 그러나 타임아웃이 발생해도 원격 노드가 응답을 받았는지 여부는 여전히 알 수 없다.
    

### 현실의 네트워크 결함

- 데이터센터처럼 제어된 환경에서도 네트워크 문제는 매우 흔하다.
    - 단일 장비의 연결, 전체 랙의 연결, 스위치 등
    - 네트워크 장비를 중복 추가하는 것은 기대만큼 결함을 줄여주지 못 한다.
    - → 주요 원인인 인적 오류로부터 보호해주지 못하기 때문
- EC2 같은 공개 클라우드 서비스는 일시적인 네트워크 결함이 자주 발생하는 것으로 악명 높다.
    - 잘 관리된 비공개 데이터센터가 더 안정적인 환경일 수 있다.
    - 그럼에도 어느쪽도 네트워크 문제를 피할 순 없다.
- 네트워크 분단
    - 네트워크 결함 때문에 일부가 다른 쪽과 차단되는 문제
    - 네트워크 분단(network partition), 네트워크 분리(netsplit), 네트워크 결함(network fault) 용어로 불림
- 네트워크 상으로 **통신할 때마다 실패할 가능성이 있으며 피할 방법은 없다**.
- 반드시 네트워크 결함을 견뎌내도록(tolerating) 처리할 필요는 없다.
- 그러나 **소프트웨어가 네트워크 문제에 어떻게 반응하는지 알고 시스템이 그로부터 복구할 수 있도록 보장해야 한다**.
- **카오스 몽키(Chaos Monkey)** 처럼 고의로 네트워크 문제를 유발하고 시스템의 반응을 테스트해보는 것도 고려할만하다.
    
    

### 결함 감지

- 시스템은 결함 있는 노드를 자동으로 감지할 수 있어야 한다.
    - LB는 죽은 노드에 요청을 그만 보내야 한다.
    - 단일 리더 복제 시스템은 리더에 장애가 나면 팔로워 중 하나를 승격시켜야 한다.
- 네트워크의 불확실성 때문에 노드가 동작 중인지 아닌지 구별하기 어려우므로 **뭔가가 동작하지 않는다**는 **명시적 피드백**을 받을 수 있다.
    - 장비에 연결은 되지만 목적지 포트에서 수신대기하는 프로세스가 없으면 OS단에서 TCP 연결을 닫거나 거부한다.
    - 노드의 프로세스가 죽었지만 OS가 실행 중이라면 OS가 다른 노드에 알려서 타임아웃까지 기다릴 필요 없이 빠르게 역할을 넘길 수 있다.
    - 데이터센터 내 네트워크 스위치의 관리 인터페이스에 접근, 질의할 수 있으면 하드웨어 수준의 링크 장애를 감지할 수 있다.
    - 라우터가 IP 주소에 도달할 수 없다고 확신하면 ICMP Destination Unreachable 패킷으로 응답할 수도 있다.
- 원격노드가 다운됐다는 빠른 피드백은 유용하지만, 여기에 의존하면 안 된다.
    - 요청이 **성공했음을 확신**하려면 **애플리케이션 자체로부터 긍정 응답을 받아야** 한다.
- 일반적으로 오류 응답이 아니라 **아무 응답도 받지 못할 것이라 가정해야 한다**.
    - 몇 번 재시도 → 타임아웃 만료 → 마침내 노드가 죽었다고 선언

### 타임아웃과 기약 없는 지연

- 긴 타임아웃과 짧은 타임아웃
    - **타임아웃이 길면** : 노드가 죽었다고 선언되기까지 오래 걸린다
    - **타임아웃이 짧으면** : 결함은 빨리 발견하지만 노드가 죽었다고 잘못 선언할 위험이 높아진다.
- 성급하게 노드가 죽었다고 선언하면 문제가 된다.
    - 실제로는 **살아있는 노드인데 죽었다고 선언**될 경우, 다른 노드가 역할을 넘겨받으면서 **같은 동작을 두 번 실행**하게 될 수도 있다.
    - 죽었다고 판단되 노드의 책무가 다른 노드로 전달돼야 해서 네트워크에 추가적인 부하를 준다.
    - 특히 **과부하** 때문에 응답이 느린 것일 경우, 부하가 다른 노드로 전달되면 **연쇄 장애**를 유발할 수 있다.
- 타임아웃을 정할 수 있는 기준
    - 패킷이 전송, 손실까지 걸리는 최대 시간 `d`
    - 장애가 나지 않은 노드가 요청을 처리하는 시간 `r`
    - 성공한 요청은 모두 `2d + r` 시간 내에 응답을 받을 수 있으므로 `2d + r` 을 타임아웃으로 사용할 수 있다.
- 비동기 네트워크는 **기약 없는 지연(unbounded delay)** 이 있고 정해진 **최대 시간 내에 요청이 처리되는 것을 보장하지도 않는다**.
- **네트워크 혼잡과 큐 대기**
    - 패킷 지연의 변동성은 **큐 대기** 때문인 경우가 많다.
        - 네트워크 스위치가 패킷을 큐에 대기시킴. 네트워크가 붐비면 패킷은 슬롯을 얻을 때까지 대기, 큐가 꽉 차면 패킷이 유실될 수도 있다. → **네트워크 혼잡(network congestion)**
        - 패킷이 목적지 장비에 도착했어도 가용 CPU가 없어 OS가 큐에 대기시킬 수 있다.
        - 가상환경OS는 다른 VM이 CPU를 사용하는 동안 수십 밀리초 단위로 멈출 때가 흔하며 가상장비 모니터가 데이터를 큐에 버퍼링한다.
        - TCP는 흐름제어(flow control, = 혼잡회피;congestion avoidance, 배압;backpressure) 를 수행하며 네트워크 과부하를 막기 위해 부가적인 큐 대기를 통해 송신율을 제한할 수 있다.
    - TCP vs UDP
        - UDP는 흐름 제어를 하지 않고, 손실된 패킷을 재전송하지 않는다.
        - 지연된 데이터가 가치가 없는 상황(재전송 필요x)에서 UDP를 선택하는 것이 좋다. (화상회의, 인터넷전화 등 지연 시간에 민감한 경우)
    - 공개 클라우드, 멀티 테넌트 데이터센터에선 여러 소비자가 자원을 공유한다.
        - 네트워크 링크, 스위치, 장비 별 네트워크 인터페이스와 CPU 등
        - 자원을 많이 사용하는 누군가 **(시끄러운 이웃)** 가 가까이 있다면 네트워크 지연 변동이 클 수 있다.
    - 자동 타임아웃 조절
        - 고정된 타임아웃 보단 **응답 시간과 변동성(지터, jitter) 을 측정하여 타임아웃을 자동으로 조절**하는 것이 더 좋은 방법이다.
        - 파이 증가 장애 감지기(Phi Accural failure detector) 를 쓸 수 있다.
        - 예시) 아카(Akka), 카산드라, TCP 재전송 타임아웃

### 동기 네트워크 대 비동기 네트워크

- 패킷 전송의 지연 시간 최대치가 고정돼 있고, 패킷 유실이 없는 네트워크는 왜 현실에서 안 쓰이는가?
- 동기식 네트워크
    - 전화 **회선(circuit)** 방식은 경로에 대해 고정된 대역폭이 할당된다.
    - 동기식 네트워크는 데이터가 여러 라우터를 거치더라도 큐 대기가 없다. (네트워크의 다음 hop에 이미 공간 할당이 되어 있음)
    - 또한 큐 대기가 없으므로 네트워크 종단 지연 시간의 최대치가 고정되어 있다.
    - 이를 **제한 있는 지연(bounded delay)** 라 한다.
- **그냥 네트워크 지연을 예측 가능하게 만들 수는 없을까?**
    - 회선은 만들어진 동안 다른 누구도 사용할 수 없는 고정된 양의 예약된 대역폭을 보장한다.
    - 반면, TCP 연결의 패킷은 **가용한 네트워크 대역폭을 기회주의적으로 사용**한다. (대역폭을 동적으로 공유)
    - 패킷 교환 방식은 **순간적으로 몰리는 트래픽(bursty traffic) 에 최적화**됐다.
        - 회선 : 통화하는 동안 초당 비트 개수가 고정된 음성, 영상 통화에 적합
        - 패킷 : 웹 페이지 요청, 이메일 전송, 파일 전송 등은 특별한 대역폭 요구사항이 없다. 빨리 완료되길 바랄뿐이다.
    - 서비스 품질(QoS), 진입 제어(admission control) 을 잘 쓰면 패킷 네트워크에서 회선 교환을 흉내낼 수는 있으나 현실적으론 어렵다.
    - 현재 기술론 네트워크 지연과 신뢰성에 대해 어떤 보장도 받을 수 없다.
        - 네트워크 혼잡, 큐 대기, 기약 없는 지연이 발생할 것을 가정해야 한다.
    - 결과적으로 **타임아웃에 올바른 값은 없으며 실험을 통해 결정**해야 한다.

## 신뢰성 없는 시계

- 애플리케이션은 **지속 시간**, **시점**을 기술하기 위해 시계에 의존한다.
    - **지속 시간** : 요청을 보낸 시점과 받은 시점 사이의 “시간 구간”
    - **시점** : 특정 시간에 발생한 이벤트
- 분산 시스템은 네트워크 지연의 변동성 때문에 통신이 즉각적이지 않으므로 시간을 다루기 까다롭다.
    - 또한 개별 장비는 자신의 시계를 갖는다.
- 흔히 **네트워크 시간 프로토콜(Network Time Protocol; NTP)** 을 사용하여 컴퓨터 시계를 조정할 수 있게 한다.
    - NTP 서버는 GPC 수신자와 같은 더욱 정확한 시간 출처로부터 시간을 얻음

### 단조 시계 대 일 기준 시계

- 현대 컴퓨터는 다른 목적으로 사용되는 두 가지 시계를 갖는다.
    - 일 기준 시계, 단조 시계
- **일 기준 시계 (time-of-day clock)**
    - 직관적으로 기대하는 시계, 현재 날짜와 시간을 반환
    - **벽시계 시간(wall-clock time)** 이라고도 한다.
    - 예시) Linux의 `clock_gettime(CLOCK_REALTIME)`, Java의 `System.currentTimeMillis()` 는 **epoch** 이래로 흐른 시간을 반환한다.
    - 보통 NTP로 동기화된다.
    - 로컬 시계가 NTP 서버보다 앞서면 강제로 리셋되면서 과거 시점으로 역행하는 것처럼 보일 수 있다. → 시계를 돌린다(slewing)
    - 이 때문에 **경과 시간을 측정한는데 적합하지 않다**.
- **단조 시계 (monotonic clock)**
    - 타임아웃, 서비스 응답 시간과 같은 **지속 시간(시간 구간) 을 재는데 적합**하다.
    - 단조 시계란 이름은 항상 앞으로 흐른다는 뜻 (일 기준 시계는 거꾸로 역행함)
    - 예시) Linux의 `clock_gettime(CLOCK_MONOTONIC)` , Java의 `System.nanoTime()` 이 있다.
    - 일반적으로 분산 시스템에선 경과 시간을 재는 데 단조 시계를 쓰는 것이 괜찮다. (다른 노드의 시계와 동기화 필요x, 약간의 부정확성에 민감하지 않음)

### 시계 동기화와 정확도

- 하드웨어 시계와 NTP의 문제점들
    - 컴퓨터의 수정 시계는 완전히 정확하지 않으며 더 빠르거나 느리게 실행되는 **드리프트(drift) 현상**이 생긴다. (장비의 온도 등에 따라)
    - 로컬과 NTP 서버의 차이가 너무 커지면 동기화가 거부되거나 로컬 시계가 강제로 리셋될 수 있다. 이 경우 애플리케이션 입장에선 시간이 역행하는 것으로 보인다.
    - 노드와 NTP 서버 사이가 방화벽으로 막혀 문제가 생길 수 있다.
    - NTP 동기화의 정확도는 패킷 지연이 심한 혼잡한 네트워크에선 한계가 있다.
    - NTP 서버 자체가 이상이 있거나 설정이 잘못돼있을 수 있다. (인터넷에서 흔히 사용되는 퍼블릭 NTP 서버들을 믿을 수 있는가?)
    - **윤초** (태양시-원자시 오차 보정을 위해 추가하는 1초) 발생 시 윤초를 고려하지 않은 시스템에선 오류가 생길 수 있다.
    - 가상장비에선 다른 VM 실행 동안 VM이 수십 밀리초씩 멈추므로 정확한 시간 계산이 더 어렵다.
    - 모바일, 임베디드 장치 등 완전히 제어할 수 없는 장치에선 하드웨어 시계를 믿기 어렵다.
- 이런 정확도는 **GPS 수신기**, **정밀 시간 프로토콜(Precision Time Protocol, PTP)** 와 세심한 배포 및 모니터링으로 달성할 수 있다.

### 동기화된 시계에 의존하기

- 소프트웨어는 네트워크 결함 뿐만 아니라, 잘못된 시계에 대해서도 대비하여 설계되고 결함을 우아하게 처리해야 한다.
- CPU 결함이나 네트워크 설정 오류 등이 발생하면 장비가 전혀 동작하지 않아 빠르게 발견 및 수리할 수 있다.
- 반면, 장비의 **수정 시계 결함**이나 **NTP 클라이언트 설정 오류**는 눈치채지 못하기 쉽다.
    - 점점 실제 시간으로부터 멀어져 가지만 대부분이 잘 동작하는 것처럼 보인다.
    - 소프트웨어가 정확히 동기화된 시계에 의존한다면 **극적인 고장보단 조용하고 미묘한 데이터 손실**을 일으킬 것이다.
- 따라서 동기화된 시계가 필요하다면 모든 장비 사이의 시계 차이를 조심스럽게 모니터링해야 한다.
- 시계 차이가 큰 노드는 죽은 것으로 선언되고 클러스터에서 제거돼야 한다.
- **이벤트 순서화용 타임스탬프 (→ 논리적 시계)**
    - 여러 노드에 걸친 이벤트들의 순서를 정하는 문제
    - 노드간 전송 지연, 복제 지연 등으로 시간과 이벤트 순서가 충돌할 수 있다.
    - 충돌 해소 전략으로 최종 쓰기 전략(LWW) 을 사용하면 문제가 생긴다.
        - DB 쓰기가 덮어쓰기로 인해 불가사의하게 사라진다. (데이터가 조용히 유실됨)
        - LWW는 순차적인 쓰기가 빠르게 연속 실행되는 것과 진짜 동시에 쓰기가 실행되는 것을 구별할 수 없다.
        - 시계 해상도가 밀리초 단위로 낮으면 두 노드가 동일한 타임스탬프 값을 가진 쓰기를 실행할 수도 있다. (어느쪽이 최종인가?)
    - 위처럼 일 기준 시계, 단조 시계와 같은 **물리적 시계(physical clock)** 을 사용하는 대신 **논리적 시계(logical clock)** 를 사용하는 것이 대안이 될 수 있다.
        - 증가하는 카운터를 기반으로 하며
        - 일 기준 시간이나 경과 초를 세지 않고 **이벤트의 상대적인 순서**만 측정
- **시계 읽기는 신뢰 구간이 있다**
    - 수정 시계의 드리프트, 네트워크 혼잡으로 인한 NTP 동기화 오차 등을 고려하면 시계 읽기를 어떤 시점으로 읽는 것은 타당하지 않을 수 있다.
    - 즉, **시간을 신뢰 구간에 속하는 범위로 읽는게 나을 수 있다**.
        - 예) 현재 시간이 해당 분의 10.3초와 10.5초 사이에 있을 가능성이 95%
    - 그러나 대부분의 시스템은 불확실성 경계를 계산하는데 필요한 불확실성 정보를 노출하지 않는다. → 즉 보통 신뢰 구간은 잘 안 쓰인다.
    - 예외적으로 스패너(Spanner)에 있는 구글 **트루타임(TrueTime) API** 가 이러한 방식을 사용한다.
        - API에 현재 시간을 요청하면 가능한 타임스탬프 범위 중 가장 이른 것과 가장 늦은 것을 반환한다.
        - 실제 현실 시간은 두 범위 사이 어딘가에 있다.
- **전역스냅숏용 동기화된 시계**
    - 스냅숏 격리 구션에는 단조 증가하는 트랜잭션 ID가 필요하다.
    - 장비가 여러 데이터센터에 분산돼 있을 땐 코디네이션이 필요하므로 **전역 단조 증가 트랜잭션 ID** 를 생성하기 어렵다.
    - 동기화가 충분히 잘 된다면 일 기준 시계의 타임스탬프를 트랜잭션 ID로 사용할 수도 있다. (단, 시계의 정확도는 여전히 불확실함)
    - 스패너는 **시계 신뢰 구간**을 이용하여 **트랜잭션 간 인과순서를 결정**한다.
        - 트루타입 API가 보고한 시계 신뢰 구간을 사용한다.
        - 두 시계 신뢰 구간이 겹치지 않는다면 순서 관계를 확실히 정할 수 있다.
        - 신뢰 구간이 겹칠 경우, 인과성을 반영하기 위해 트랜잭션 커밋 전에 의도적으로 신뢰 구간의 길이만큼 기다린다.

### 프로세스 중단

- 분산 시스템에서 시계를 위험하게 사용하는 예를 들어보자
    - DB의 각 파티션 별로 리더가 있고, 노드가 여전히 리더인지 + 리더가 쓰기를 받아들일 수 있는지 알기 위해 **임차권(lease)** 을 사용한다고 가정해보자.
    - 특정 시점에 한 리더만 임차권을 얻을 수 있다.
    - 임차권 만료까진 자신이 리더이며 계속 리더로 남으려면 만료 전에 갱신해야 한다.
    - 노드에 장애가 나면 갱신이 멈추므로 만료 시 다른 노드로 리더 역할이 넘어간다.
    
    ```java
    while (true) {
    	request = getIncomingRequest();
    
    	// 항상 임차권이 적어도 10초는 남아 있게 보장한다.
    	if (lease.expiryTimeMillis - System.currentTimeMillis() < 10000) {
    		lease = lease.renew();
    	}
    
    	if (lease.isValid()) {
    		process(request);
    	}
    
    }
    ```
    
- 위 코드의 문제점
    1. 동기화된 시계에 의존한다.
        - 임차권 만료 시간은 다른 장비에서 설정됨
        - 이를 로컬 시계와 비교함
    2. 루프 도중에 프로세스가 중단될 경우 예상치 못한 오류를 일으키게 된다.
        - lease.isValid() 직후 프로그램이 10초 넘게 중단될 경우,
        - 이미 임차권이 만료되어 리더 역할이 다른 노드로 넘어간다. (즉, 다른 노드에서 요청을 처리했다.)
        - 그러나 이 코드는 그 사실을 알아차리지 못하고 요청을 처리해버린다.
- 스레드가 아주 오랫동안 멈출 수 있는 다양한 이유
    - **가비지 컬렉터(garbage collector; GC)** 로 인한 stop-the-world
    - 가상 환경 장비의 빈번한 **서스펜드(suspend)** 와 **재개(resume)**
    - 노트북 등 기기에선 실행이 제멋대로 서스펜드, 재개될 수 있다. (덮개 닫기)
    - OS가 다른 스레드로 **컨텍스트 스위치**하거나 **하이퍼바이저가 다른 가상 장비로 스위치**되면 스레드가 멈출 수 있다.
        - (tip) 가상 장비의 경우 다른 가상 장비에서 소비된 CPU 시간을 **스틸 타임(steal time)** 이라고 한다.
    - 애플리케이션이 동기식으로 디스크 접근 시 느린 **디스크I/O 연산**이 완료되기를 기다리느라 중단될 수 있다.
    - OS가 디스크로 **스왑(페이징)** 을 한다면 디스크→메모리로 로딩하는 **페이지 폴트**가 발생하여 마찬가지로 느린 디스크I/O 연산으로 인해 스레드가 멈춘다.
        - (tip) OS가 페이지를 스와핑하느라 대부분의 시간을 쓰는 것을 **스래싱(thrashing)** 이라 한다.
- 단일 장비에서 다중 스레드 코드를 작성할 때 스레드 세이프하게 작성 가능하다.
    - 뮤텍스(mutex), 세마포어(semaphore), 원자적 카운터(atomic counter), 잠금 없는(lock-free) 자료구조, 블로킹 큐(blocking queue) 등 활용하여
- 그러나 분산 시스템에선 이런 해결방법을 사용할 수 없다.
    - 공유 메모리가 없고 신뢰성 없는 네트워크를 통해 메시지를 보낼 수 만 있다.
- 따라서 **분산 시스템의 노드는 어느 시점에 실행이 오랫동안 멈출 수 있다고 가정해야 한다**.
- **응답 시간 보장**
    - 응답 시간 보장을 위해 스레드와 프로세스가 중단되는 원인을 제거할 수도 있다.
    - **엄격한 실시간 시스템(hard real-time)**
        - 소프트웨어가 응답해야 하는 데드라인(deadline)이 명시된다.
        - 데드라인을 만족시키지 못하면 전체 시스템 장애를 유발할 수 있다.
        - 예시) 항공기, 로켓, 로봇, 자동차 등
    - 시스템에서 실시간 보장을 제공하려면 **실시간 운영체제(real-time os, RTOS)** 가 필요하다.
        - 프로세스가 명시된 간격의 CPU 시간을 할당받을 수 있게 보장되도록 스케줄링해준다.
        - 라이브러리 함수는 최악의 실행 시간 문서화해야하며며
        - 동적 메모리 할당은 제한 또는 금지되고
        - 막대한 양의 테스트와 측정을 해야 한다.
    - 대부분의 서버측 데이터 처리 시스템에게 실시간 보장은 전혀 경제적이지도, 적절하지도 않다. (즉 특수한 케이스에만 적용됨)
- **가비지 컬렉션의 영향을 제한하기**
    - 실시간 스케줄링 없이도 프로세스 중단 영향을 완화시킬 수 있다.
    - 언어 런타임은 객체 할당률과 여유 메모리 공간을 추적할 수 있으므로 **언제 GC할지에 대한 유연성**을 가지고 있다.
    - 최근 아이디어로, 노드 GC 동안 요청을 다른 노드에서 처리하도록 하는 방법이 있다.
        - GC 중단을 클라이언트로부터 감추고 응답 시간의 상위 백분위를 줄여준다.
    - 변종 아이디어로, 수명이 짧은 객체만 GC하고, 전체 GC가 필요할 만큼 객체가 쌓이기 전에 주기적으로 프로세스를 재시작하는 방법이 있다.
        - 순회식 업그레이드처럼 계획된 재시작 사용


## 지식, 진실, 그리고 거짓말

- 분산 시스템은 공유 메모리가 없고 지연 변동이 큰 신뢰할 수 없는 네트워크로 메시지를 보내야한다.
- 때문에 부분 장애, 신뢰성 없는 시계, 프로세스 중단 문제를 겪게 된다.
- 분산 시스템에선 동작( **시스템 모델** )에 관해 가정을 정하고, 이런 가정을 만족시키는 방법으로 실제 시스템을 설계할 수 있다.

### 진실은 다수결로 결정된다

- 분산 시스템에선 노드가 상황에 대한 자신의 판단도 믿어선 안 된다.
    - GC로 인해 긴 stop-the-world 중단을 겪을 경우, 외부에선 해당 노드가 응답이 없어 죽은 상태로 간주하지만 GC가 끝나면 노드 입장에선 시간이 흐르지 않았으므로 자신이 죽음처리되었다는 것을 모른다.
- 때문에 분산 알고리즘에선 보통 **정족수(quorum)** 즉 노드들 사이의 투표에 의존한다.
    - 노드의 과반수 이상을 정족수로 삼는게 가장 흔하다.
- **리더와 잠금 (스스로를 선택된 자로 잘못 아는 문제)**
    - 단 하나의 노드(사용자)만이 무언가를 얻거나 행동해야하는 경우가 있다.
        - **스플릿 브레인**을 피하기 위해 한 노드만 파티션 리더가 될 수 있다.
        - 동시 쓰기 등으로 객체가 오염되는걸 막기 위해 한 트랜잭션만 **객체의 잠금을 획득**할 수 있다.
        - **사용자를 식별**하기 위해 오직 한 명의 사용자만 특정 사용자명으로 등록할 수 있다.
    - 위와 같은 상황들에서 어떤 노드가 **죽었다고 선언**했음에도 그 노드가 **계속 선택된 자인 것처럼 계속 행동**한다면 시스템에 문제를 유발할 수 있다.
    - HBase에서 발생했던 잠금과 관련된 클라이언트 쓰기 충돌 문제
        - 클라1은 자신이 얻은 잠금이 gc로 인해 만료됐음을 알지 못하고 쓰기를 수행해 파일을 오염시킴

![image](https://github.com/dhkdn9192/data_engineer_career/assets/11307388/3720a026-781c-42c3-bf68-f367ef3cc407)

- **펜싱 토큰**
    - 리소스에 대한 접근을 보호하기 위해 잠금이나 임차권을 쓸 때, 자신이 ”선택된 자“라고 잘못 믿는자가 시스템을 방해할 수 없도록 보장해야 한다.
    - 이를 위한 단순한 기법으로 **펜싱(fencing)** 이 있다.
    - 잠금 서버가 잠금(임차권)을 승인할 때마다 단조 증가하는 **펜싱 토큰(fencing token)** 도 반환한다.
    - 저장소에선 이미 처리한 토큰 번호를 기억하여, 더 작은 토큰 번호를 가진 쓰기(만료된 임차권) 요청이 오면 거부한다.
    - 잠금 서비스로 **주키퍼**를 사용하면 트랜잭션 ID `zxid` 나 노드버전 `cversion` 을 펜싱 토큰으로 사용한다.

![image](https://github.com/dhkdn9192/data_engineer_career/assets/11307388/e365cf99-ba33-4a7d-a2cd-6cf5ff951644)

### 비잔틴 결함

- 일부 노드가 오작동하고 프로토콜을 준수하지 않거나 악의적인 공격자가 네트워크를 방해하더라도 시스템이 올바르게 동작한다면 **비잔틴 내결함성을 지닌다(Byzantine fault-tolerant)**
- **비잔틴 결함(Byzantine fault)** :
    - 분산 시스템의 노드가 거짓말(임의의 결함 또는 오염된 응답)을 할 수도 있다는 결함을 의미
    - 예시) 실제로는 받지 않은 메시지를 받았다고 주장
- **비잔틴 장군 문제(Byzantine Generals Problem)** : 이러한 신뢰할 수 없는 환경에서 합의에 도달하는 문제
- 비잔틴 내결함성이 유의미한 케이스
    - 항공우수 산업 환경에선 메모리나 레지스터의 데이터가 방사선에 오염되어 컴퓨터가 예측 불가능한 방식으로 반응할 수 있다.
    - 여러 조직이 참여하는 시스템에선 악의적인 목적으로 다른 사람을 속이려는 참여자가 존재할 수 있다.
- 대부분의 서버 측 데이터 시스템에서 비잔틴 내결함성 솔루션을 배치하는 것은 비용이 커서 실용적이지 않다.
- 반면 웹 애플리케이션은 클라이언트의 행동이 악의적이라고 예상해야 한다.
    - SQL injection, cross site scripting 등
    - 따라서 입력 확인(input validation), 살균(sanitization), 출력 이스케이핑(output escaping)이 중요하다.
- 대부분의 비잔틴 내결함성 알고리즘은 노드의 2/3 이상의 압도적 다수가 올바르게 동작하기를 요구한다.

### 약한 형태의 거짓말

- 약한 형태의 거짓말(HW문제, SW버그, 잘못된 설정으로 유효하지 않게된 메시지 등)로부터 보호해주는 메커니즘을 SW에 추가하는 것이 유효할 수도 있다.
- 완전한 비잔틴 내결함성을 지니진 않지만 신뢰성 향상을 위한 간단하고 실용적인 방법이다.
- 예시
    - 네트워크 패킷이 HW, OS, 네트워크 과정의 버그로 오염될 수 있다. 이런 오염을 피하기 위해 애플리케이션 수준 프로토콜에서 **체크섬**을 쓰는 단순한 수단을 사용할 수 있다.
    - 공개적으로 접근 가능한 애플리케이션은 **사용자 입력**을 신중하게 **살균**해야 한다. 입력값에 대해 기본적인 **정상성 점검(sanity-checking)** 을 하는게 좋다.
    - NTP 클라이언트는 여러 서버 중 잘못된 시간을 보고하는 NTP 서버를 outlier로 검출하여 동기화 대상에서 제거할 수 있다.

### 시스템 모델과 현실

- **시스템 모델(system model)** 을 정의함으로써 시스템에서 발생할 수 있는 결함의 종류를 정형화할 수 있다.
- **타이밍** 가정에 대한 세 가지 시스템 모델
    - **동기식 모델**
        - 네트워크 지연, 프로세스 중단, 시계 오차에 모두 제한이 있다고 가정
        - 지연과 중단, 시계 드리프트가 어떤 상한치를 초과하지 않는다고 가정
        - 현실에선 기약 없는 지연과 중단이 발생하므로 대부분의 시스템에선 비현실적인 모델이다.
    - **부분 동기식 모델**
        - 대부분의 시간에는 동기식 모델처럼 동작하지만 때때로 네트워크 지연, 프로세스 중단, 시계 드리프트의 한계치를 초과한다고 가정
        - 많은 시스템에서 현실적인 모델
    - **비동기식 모델**
        - 타이밍에 대한 어떤 가정도 할 수 없으며 심지어 시계가 없을 수도 있음
        - 비동기식 모델용으로 설계할 수 있는 알고리즘은 매우 제한적이다.
- **노드 장애**에 대한 세 가지 시스템 모델
    - **죽으면 중단(crash-stop) 하는 결함**
        - 노드에 장애 유형이 죽는 것 하나 뿐이라고 가정
        - 노드가 응답하길 멈추면 영원히 사용할 수 없고 되돌아오지 않음
    - **죽으면 복구(crash-recovery) 하는 결함**
        - 죽어도 임의의 시간이 흐르면 다시 응답하기 시작할 것이라고 가정
        - 메모리의 데이터는 손실돼도 비휘발성 디스크 저장소에는 데이터가 남아있다고 가정
    - **비잔틴(임의적인) 결함**
        - 다른 노드를 속이는 등 전적으로 무슨 일이든 발생할 수 있다고 가정

### 알고리즘의 정확성

- 알고리즘이 정확하다(correct) 의 의미를 정의하기 위해 알고리즘의 속성(property) 를 기술할 수 있다.
- 예시) 잠금에 펜싱 토큰을 생성한다면 그 알고리즘은 다음 속성을 지녀야 한다.
    - 유일성 : 펜싱 토큰이 같은 값을 반환하지 않는다.
    - 단조 일련번호 : 요청에 따른 토큰들은 순서에 따라 증가, t1 < t2를 만족한다.
    - 가용성 : 펜싱 토큰을 요청하고 죽지 않은 노드는 결국엔 응답을 받는다.
- 알고리즘은 시스템 모델에서 발생하리라 가정한 모든 상황에서 **그 속성들을 항상 만족**시키면 → **해당 시스템 모델에서 정확하다** 라고 할 수 있다.

### 안전성과 활동성

- 상황을 분명히 하기 위해 안전성(safety) 과 활동성(liveness) 을 구별할 필요가 있다.
    - 안전성 : 비공식적으로 나쁜 일은 일어나지 않는다
    - 활동성 : 좋은 일은 결국 일어난다

## 정리

- 분산 시스템에서 일어날 수 있는 광범위한 문제들
    - 네트워크 상에서 패킷은 손실, 지연될 수 있다. 응답을 받지 못 하면 메시지가 전달됐는지 조차도 알 수 없다.
    - 노드의 시계는 동기화 문제를 겪을 수 있고, 갑자기 시간이 앞뒤로 뛸 수도 있다. 이런 문제들로 시계에 의존하는 것은 위험하다.
    - 프로세스는 GC 등으로 상당 기간 멈출 수 있고, 다른 노드에 의해 죽었다고 선언될 수 있으며, 되살아났을 때 멈췄었다는 사실을 알지 못할 수도 있다.
- **부분 실패(partial failure)** 는 분산 시스템의 특징이다.
    - 가끔씩 실패하거나 임의로 느려지거나 전혀 응답하지 않을 수 있다.
    - 따라서 부분 실패에 대한 내성을 SW에 내장하도록 해야 한다.
- 분산 시스템에선 결함을 감지하는 것조차도 어려우며 원격 노드가 가용 상태인지 결정하기 위해 일반적으로 **타임아웃**을 사용한다.
- 분산 시스템에선 단일 노드가 안전하게 중대한 결정을 할 수 없으므로 다른 노드의 도움을 요청하고 동의할 **정족수**를 이루려고 시도한다.
