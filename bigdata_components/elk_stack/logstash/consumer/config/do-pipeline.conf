# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  kafka {
    bootstrap_servers => "cloudera-node1:9092,cloudera-node2:9092,cloudera-node3:9092"
    topics => ["do-user-access-log","do-admin-access-log","do-imap-log","do-mail-log"]
    group_id => "logstash"
    consumer_threads => 1
    decorate_events => true
    codec => json{}
  }
}

filter {

  #DO User Access Filter
  if [@metadata][kafka][topic] == "do-user-access-log" or "do-admin-access-log" {

    #도메인 필드 초기화
    mutate { 
      remove_field => ["domain"] 
    }

    grok {
      match => { "message" => "%{NOTSPACE:clientip} %{NOTSPACE:thread} %{NOTSPACE:trash} (%{NOTSPACE:email}) \[%{HTTPDATE:timestamp}\] %{WORD:method} %{NOTSPACE:api} %{NOTSPACE:version} %{NUMBER:code:int} %{NOTSPACE:bytes:int} %{QUOTEDSTRING:wrapper} %{QUOTEDSTRING:agent} %{QUOTEDSTRING:client} %{NUMBER:duration:float}"
      }
    }
    # favicon 은 인덱싱 제외 - webmail
    if [api] == "/favicon.ico" {
      drop { }
    }
    # favicon 은 인덱싱 제외 - webadmin
    if [api] == "/go/favicon.ico" {
      drop { }
    }
    # 위치정보 입력
    geoip {
      source => "clientip"
    }   
    # "" 문자 제거
    mutate {
      gsub => [ "wrapper", "\"", "", "client", "\"", "", "agent", "\"", "" ]
    }
    useragent {
      source => "agent" target => "ua"
    }
    if [agent] =~ "^GO-" {
      mutate {
        update => {
          "[ua][os]" => "%{agent}"
        }
      }
    }
    # 메뉴 이름 추출(ex:approval, board, home)
    mutate {
      copy => {
        "wrapper" => "wrapper_tmp"
      }
    }
    if [wrapper_tmp] =~ "^.*daouoffice.com\/app\/.*" {
      mutate {
        split => {"wrapper_tmp" => "/"}
        add_field => { "appname" => "%{wrapper_tmp[4]}" }
      }
    }        
    if [wrapper_tmp] =~ "^.*daouoffice.com:8443\/go\/.*" {
      mutate {
        split => {"wrapper_tmp" => "/go"}
        add_field => { "appname" => "%{wrapper_tmp[1]}" }
      }
    }
    mutate { copy => { "appname" => "appname_tmp" } }
    if [appname] =~ "[?]" {
      mutate {
        split => { "appname_tmp" => "?" }
      }  
      mutate {
        update => { "appname" => "%{appname_tmp[0]}" }
      }
    }
    #회사구분을 위한 도메인 정보 출력
    mutate {
      copy => { "email" => "email_tmp" }
    }
    if [email_tmp] != "-" {
      mutate {
        split => { "email_tmp" => "@" }
        add_field => { "domain" => "%{email_tmp[1]}" }
      }
    }       
    #API 파라미터 삭제
    mutate {
      copy => { "api" => "api_tmp" }
    }     
    if [api_tmp] =~ "[?]" {
      mutate {
        split => { "api_tmp" => "?" }
      }
      mutate {
        update => { "api" => "%{api_tmp[0]}" }
      }
    }
    #시간 기준으로 INDEX 생성
    date { 
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ] timezone => "Asia/Seoul" target => "@timestamp" 
    }
    #불필요한 필드 삭제
    mutate { remove_field => ["email_tmp", "api_tmp", "trash", "wrapper_tmp", "appname_tmp", "dir", "path"] }
  }

  # IMAP Filter
  if [@metadata][kafka][topic] == "do-imap-log" {
    #도메인 필드 초기화
    mutate { 
      remove_field => ["domain"] 
    }

    grok { 
      match => { "message" => "\[%{NOTSPACE:logtime} %{NOTSPACE:trash}\] -%{LOGLEVEL:loglevel} MU:%{NOTSPACE:email} CMD:%{NOTSPACE:cmd} DS:%{NOTSPACE:ds} time: %{BASE16FLOAT:elapsed:float} elapsed" }
    }
    # 사용하지 않는 로그 인덱싱 제거
    if [loglevel] != "DEBUG" { 
      drop { } 
    }
    #파일명에서 날짜 추출
    mutate { 
      copy => { "file_name" => "file_name_tmp" } 
    }
    mutate { 
      split => { "file_name_tmp" => "." } 
      add_field => { "logdate" => "%{file_name_tmp[0]}" } 
    }
    mutate { 
      update => { "logdate" => "%{logdate} %{logtime}" } 
    }
    date { 
      match => ["logdate", "yyyyMMdd HH:mm:ss"] timezone => "Asia/Seoul" target => "@timestamp" 
    }
    # :문자 제거
    mutate {
      gsub => [ "ds", ":", "","email", ":", "","cmd", ":", "" ]
    }
    #회사구분을 위한 도메인 정보 출력
    mutate {
      copy => { "email" => "email_tmp" }
    }
    mutate {
      split => { "email_tmp" => "@" }
      add_field => { "domain" => "%{email_tmp[1]}" }
    }
    #미사용 컬럼 삭제
    mutate { 
      remove_field => ["file_name_tmp", "logtime", "trash", "email_tmp"] 
    }
  }

  # Mail Filter
  if [@metadata][kafka][topic] == "do-mail-log" {
    #도메인 필드 초기화
    mutate { 
      remove_field => ["domain"] 
    }

    # ruby 플러그인 코드 호출
    ruby {
      path => "/opt/share/logstash/plugins/filter_mail_log.rb"
      script_params => { "source_field" => "message" }
    }

    # 유효하지 않은 로그는 drop
    if [VALID] != "1" {
      drop { }
    }

    # 파일명에서 날짜 추출
    mutate {
      copy => { "file_name" => "file_name_tmp" }
      gsub => ["file_name_tmp", ".log", ""]
      add_field => { "logdate" => "%{file_name_tmp}" }
      update => { "logdate" => "%{logdate} %{logtime}" }
    }
    date {
      match => ["logdate", "yyyyMMdd HH:mm:ss"] timezone => "Asia/Seoul" target => "@timestamp"
    }

    # 미사용 필드 제거
    mutate {
      remove_field => ["VALID", "file_name_tmp", "logtime", "logdate"]
    }
  }
}

output {

  if [@metadata][kafka][topic] == "do-user-access-log" {
    elasticsearch {
      hosts => ["http://cloudera:9200", "http://cloudera-node1:9200", "http://cloudera-node2:9200", "http://cloudera-node3:9200", "http://cloudera-node4:9200"]
      index => "logstash-do-user-%{file_name}"
    }
  }

  if [@metadata][kafka][topic] == "do-admin-access-log" {
    elasticsearch {
      hosts => ["http://cloudera:9200", "http://cloudera-node1:9200", "http://cloudera-node2:9200", "http://cloudera-node3:9200", "http://cloudera-node4:9200"]
      index => "logstash-do-admin-%{file_name}"
    }
  }

  if [@metadata][kafka][topic] == "do-imap-log" {
    elasticsearch {
      hosts => ["http://cloudera:9200", "http://cloudera-node1:9200", "http://cloudera-node2:9200", "http://cloudera-node3:9200", "http://cloudera-node4:9200"]
      index => "logstash-do-imap-%{file_name}"
    }
  }

  if [@metadata][kafka][topic] == "do-mail-log" {
    elasticsearch {
      hosts => ["http://cloudera:9200", "http://cloudera-node1:9200", "http://cloudera-node2:9200", "http://cloudera-node3:9200", "http://cloudera-node4:9200"]
      index => "logstash-do-mail-%{file_name}"
    }
  }

  # ---- webhdfs ----

#  if [@metadata][kafka][topic] == "do-user-access-log" {
#    webhdfs {
#      host => "cloudera-node1"
#      port => 50070
#      path => "/user/hdfs/do-user-access-log/%{cluster}/%{[beat][hostname]}/%{file_name}/%{[@metadata][thread_id]}"
#      single_file_per_thread => "true"
#      codec => 'json'
#      user => "hdfs"
#    }
#  }
#
# if [@metadata][kafka][topic] == "do-admin-access-log" {
#   webhdfs {
#     host => "cloudera-node1"
#     port => 50070
#     path => "/user/hdfs/do-admin-access-log/%{cluster}/%{[beat][hostname]}/%{file_name}/%{[@metadata][thread_id]}"
#     single_file_per_thread => "true"
#     codec => 'json'
#     user => "hdfs"
#   }
# }
#
# if [@metadata][kafka][topic] == "do-imap-log" {
#   webhdfs {
#     host => "cloudera-node1"
#     port => 50070
#     path => "/user/hdfs/do-imap-log/%{cluster}/%{[beat][hostname]}/%{file_name}/%{[@metadata][thread_id]}"
#     single_file_per_thread => "true"
#     codec => 'json'
#     user => "hdfs"
#   }
# }
#
# if [@metadata][kafka][topic] == "do-mail-log" {
#   webhdfs {
#     host => "cloudera-node1"
#     port => 50070
#     path => "/user/hdfs/do-mail-log/%{cluster}/%{[beat][hostname]}/%{file_name}/%{[@metadata][thread_id]}"
#     single_file_per_thread => "true"
#     codec => 'json'
#     user => "hdfs"
#   }
# }
}
