# Week04 - Summary


### 1. RDD를 사용해 filter와 join을 할 때 어떤 순서로 쓰는 것이 더 빠르고 그 이유를 설명해주세요.

filter를 먼저 적용한 후 join을 쓰는 것이 빠르다.
join은 shuffle을 유발하므로 네트워크를 이동하는 데이터의 양을 줄이기 위해 filter를 먼저 사용한다.

### 2. RDD와 Database/Hive에서 각각 다루는 데이터의 종류는 어떤 차이가 있나요?

RDD는 구조화되지 않은 데이터를, Databae/Hive는 구조화된 데이터를 다룬다.
구조화되지 않은 데이터는 스키마를 고려하지 않으며 임의의 데이터 타입을 사용한다.
구조화된 데이터는 고정된 칼럼과 값의 타입 등 데이터의 구조 명시되어 있다.

### 3. Spark SQL의 세가지 목적을 써주세요.

1. Spark 프로그램(RDDs)과 외부 데이터 소스 사이의 관계형 프로세싱을 간편한 API를 통해 지원한다.
2. 데이터베이스 분야의 기술을 사용하여 높은 성능을 제공한다.
3. 반 구조화된 데이터 및 외부 데이터베이스 같은 신규 데이터소스도 손쉽게 다룰 수 있다.

### 4. Dataframe 은 무엇인가요?

개념상 레코드들이 모두 알려진 스키마를 갖는 RDD로, 관계형 데이터베이스의 테이블과 동일하다.
데이터프레임의 Row들은 사용자가 지정한 형태의 스키마를 갖는다.

### 5. DataFrame을 사용해 filter와 join을 할 때 어떤 순서로 쓰는 것이 더 빠르고 그 이유를 설명해주세요.

상관 없다. Spark SQL은 카탈리스트가 연산을 재조정함으로써 최적화를 수행하기 때문이다.

### 6. 카탈리스트가 최적화 해주는 부분 세가지를 써주세요.

1. 연산 재조정
2. 연산에 사용되지 않는 데이터는 읽지 않음으로써 사용할 데이터의 양을 줄여줌
3. 연산에 사용되지 않는 파티셔닝 제거

### 7. DataFrame의 제한점 (limitations) 세가지를 요약해 주세요 

1. Untyped. 데이터프레임의 레코드인 Row는 타입으로 파라미터화되지 않으므로 
스칼라 컴파일러가 Spark SQL 스키마에 대한 타입을 검사할 수 없다.
2. 데이터 타입이 제한적이다.
3. 반 구조화 또는 구조화된 데이터를 필요로 한다.

### 8. 데이터 셋은 무엇인가요?

타입이 지정된 분산 데이터 컬랙션이다.
구조화 또는 반 구조화된 데이터를 필요로한다.
데이터프레임보다 타입 정보를 더 많이 가지며 RDD보다 더 최적화 가능하다.
즉 데이터프레임과 RDD의 절충안과도 같다.

### 9. Dataset의 operation는 map과 select 중 카탈리스트가 최적화 할 수 있는 무엇이고 왜 그런가요?

select는 정해진 타입, 칼럼에 대해서만 연산을 수행하므로 카탈리스트에 의해 최적화될 수 있다.
반면 map은 리터럴 함수, 람다 함수와 같은 함수형 연산이 사용되므로 카탈리스트에 의해 최적화될 수 없다.

### 10. 같은 operation을 하더라도 Dataset이 RDD보다 더 좋은 성능을 낼 수 있는 이유를 써주세요 (힌트: Tungsten)

Dataset은 Tunsten으로 데이터를 직렬화한다. 
RDD와는 달리 데이터가 스키마를 가지며 데이터의 형태가 고정되므로
보다 최적화된 직렬화가 가능하다.
