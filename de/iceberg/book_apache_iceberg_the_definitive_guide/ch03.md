# Chapter 03. Lifecycle of Write and Read Queries

(Chapter 2 복기) Iceberg는 다음과 같이 3개의 계층으로 구분된다.
![image](https://github.com/user-attachments/assets/1c846902-39c5-4355-8ec8-2f03a9edaadb)

**카탈로그 계층**
- 카탈로그는 current metadata pointer를 참조하며 이는 각 테이블의 최신 메타데이터 파일을 의미한다.
- 쿼리엔진은 읽기든 쓰기든 상관없이 가장 먼저 카탈로그와 상호작용한다.
  - 읽기의 경우: 테이블의 현재 상태를 확인하기 위해 카탈로그를 참조
  - 쓰기의 경우: 정의된 스키마를 준수하고 파티셔닝 스키마를 확인하기 위해 카탈로그를 참조

**메타데이터 계층**
- 메타데이터 파일, manifest 리스트, manifest 파일로 구성된다.
- 쿼리엔진이 테이블에 쓰기를 수행할 때 마다 새로운 메타데이터 파일이 자동 생성되고 가장 최신버전으로 정의된다.
  - 이는 테이블 커밋의 선형기록을 보장하고 동시쓰기와 같은 상황을 해결할 수 있게 해준다.
  - 또한 읽기 작업 시 항상 테이블의 최신 버전을 볼 수 있게 해준다.
- 쿼리엔진은 manifest 리스트를 통해 읽을 필요없는  manifest 파일들을 skip하여 빠른 성능을 낼 수 있다.
- 쿼리엔진은 manifest 파일의 정보를 통해 파일 프루닝을 할 수 있다.
  - 칼럼별 상한 및 하한, null 값 카운트, 파티션 데이터 등

**데이터 계층**
- 쿼리엔진은 파티셔닝 쿼리에 필요한 데이터파일을 읽기 위해 메타데이터 파일을 필터링한다.
- 쓰기 작업에선 데이터파일이 파일 스토리지에 작성되고, 이어서 관련된 메타데이터 파일이 생성 및 업데이트된다.




## Writing Queries in Apache Iceberg

Iceberg의 쓰기는 다음과 같이 수행된다.
- 쓰기 쿼리가 시작되면 쿼리엔진이 이를 파싱한다.
- 쿼리엔진은 데이터의 일관성과 무결성을 보장하고 데이터를 파티션 전략에 맞게 쓰기 위해 카탈로그를 참고한다.
- 데이터파일과 메타데이터파일이 쿼리에 따라 작성된다.
- 최종적으로 카탈로그 파일이 최신 메타데이터를 반영하도록 업데이트된다. 이후로 수행되는 읽기 작업은 가장 최신 버전의 데이터에 접근하게 된다.

![image](https://github.com/user-attachments/assets/fc543a7c-a174-4dd5-bf4f-a9cb71d42cd7)


### Create the Table

spark-sql을 실행한다.
해당 서버 내에 spark 3.5.2가 설치되어 있고 원격 하둡에 연결되도록 세팅되어 있는 환경이다.
```bash
./bin/spark-sql --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.1 \
--conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
--conf spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog \
--conf spark.sql.catalog.spark_catalog.type=hive \
--conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog \
--conf spark.sql.catalog.local.type=hadoop \
--conf spark.sql.catalog.local.warehouse=/my/hdfs/path/for/iceberg/catalog \
--archives jdk11.tar.gz#jdk11 \
--conf spark.yarn.appMasterEnv.JAVA_HOME=./jdk11 \
--conf spark.executorEnv.JAVA_HOME=./jdk11
```

spark-sql 콘솔에서 local 카탈로그 선택한다.
```
spark-sql (default)> use local;
Time taken: 0.718 seconds
spark-sql ()>
```

테이블 생성 쿼리를 실행한다.
```sql
# Spark SQL
CREATE TABLE orders (
order_id BIGINT,
customer_id BIGINT, order_amount DECIMAL(10, 2), order_ts TIMESTAMP
)
USING iceberg
PARTITIONED BY (HOUR(order_ts))
```

local 카탈로그 경로에 메타데이터 json 파일이 생성된다. (`/my/hdfs/path/for/iceberg/catalog/v1.metadata.json`)

<details>
<summary>v1.metadata.json 펼쳐보기</summary>

```json
{
  "format-version" : 2,
  "table-uuid" : "47ed1b81-17e0-49bb-bd69-eabff2d020cf",
  "location" : "/my/hdfs/path/for/iceberg/catalog/orders",
  "last-sequence-number" : 0,
  "last-updated-ms" : 1736229455394,
  "last-column-id" : 4,
  "current-schema-id" : 0,
  "schemas" : [ {
    "type" : "struct",
    "schema-id" : 0,
    "fields" : [ {
      "id" : 1,
      "name" : "order_id",
      "required" : false,
      "type" : "long"
    }, {
      "id" : 2,
      "name" : "customer_id",
      "required" : false,
      "type" : "long"
    }, {
      "id" : 3,
      "name" : "order_amount",
      "required" : false,
      "type" : "decimal(10, 2)"
    }, {
      "id" : 4,
      "name" : "order_ts",
      "required" : false,
      "type" : "timestamptz"
    } ]
  } ],
  "default-spec-id" : 0,
  "partition-specs" : [ {
    "spec-id" : 0,
    "fields" : [ {
      "name" : "order_ts_hour",
      "transform" : "hour",
      "source-id" : 4,
      "field-id" : 1000
    } ]
  } ],
  "last-partition-id" : 1000,
  "default-sort-order-id" : 0,
  "sort-orders" : [ {
    "order-id" : 0,
    "fields" : [ ]
  } ],
  "properties" : {
    "owner" : "irteam",
    "write.parquet.compression-codec" : "zstd"
  },
  "current-snapshot-id" : -1,
  "refs" : { },
  "snapshots" : [ ],
  "statistics" : [ ],
  "partition-statistics" : [ ],
  "snapshot-log" : [ ],
  "metadata-log" : [ ]
}
```

</details>

테이블 고유 식별자가 `table-uuid` 필드에 부여된다.
아직 빈 테이블만 생성했기 때문에 datafile이 없고
따라서 스냅샷은 아무 manifest 리스트도 가리키지 않으며 따라서 manifest 파일도 없는 상태다.
(`current-snapshot-id`가 -1이고 `snapshots`이 빈 리스트 상태임)

local 카탈로그 타입을 hadoop으로 지정했기 때문에 같은 디렉토리에 `version-hint.text` 파일이 생성된다.
스냅샷 번호를 가리키는 카탈로그 파일이며 현재 `v1.metadata.json` 만 존재하므로 `version-hint.text` 값은 `1` 이다.

![image](https://github.com/user-attachments/assets/b2a5879b-a422-4d6d-9965-29a4612a62ca)




### Insert the Query
다음과 같이 레코드 하나를 추가하는 INSERT 명령을 수행한다.
```sql
INSERT INTO orders VALUES ( 
       123,
       456,
       36.17,
       cast('2023-03-07 08:10:23' as timestamp)
); 
```

INSERT 명령이 수행되는 순서는 다음과 같다.
- 쿼리엔진은 먼저 catalog로부터 현재 메타데이터 파일을 확인한다.(`version-hint.txt` 파일이 `1`을 가리키고 있음)
- 그 다음 데이터파일 및 관련 메타데이터 파일들을 생성한다.
  - datafile을 parquet 파일로 생성한다.
  - manifest 파일을 avro 파일로 생성한다.
    - manifest 파일은 parquet 데이터파일의 경로와 데이터의 통계 정보를 포함한다. (칼럼별 상하한, null 카운트 등)
  - manifest list를 avro 파일로 생성한다.
    - manifest 파일의 경로, 추가/삭제된 데이터파일의 수, 칼럼별 상하한과 같은 파티션 통계정보 등을 포함한다.
  - metadata 파일을 json 파일로 생성한다.
    - 스냅샷 번호가 1 증가된 `v2.metadata.json`로 생성되며 앞서 생성된 manifest list 등의 정보를 포함한다.
- 쿼리엔진은 다시 catalog로 가서 INSERT 명령 수행 중 다른 스냅샷이 커밋되지 않았는지 확인하는 validation 작업을 수행한다.
  - 다수의 사용자에 의한 동시성 문제에도 명령 수행이 방해받지 않도록 보장해준다.
- 테이블 메타데이터 파일 포인터가 `v2.metadata.json`를 가리키도록 변경한다.

![image](https://github.com/user-attachments/assets/0a00b192-d356-4560-a29c-13fd223ce2e7)


새로 추가된 `v2.metadata.json` 메타데이터 파일 내용은 다음과 같다.

<details>
<summary>v2.metadata.json 펼쳐보기</summary>

```json
{
  "format-version" : 2,
  "table-uuid" : "47ed1b81-17e0-49bb-bd69-eabff2d020cf",
  "location" : "/my/hdfs/path/for/iceberg/catalog/orders",
  "last-sequence-number" : 1,
  "last-updated-ms" : 1736230211856,
  "last-column-id" : 4,
  "current-schema-id" : 0,
  "schemas" : [ {
    "type" : "struct",
    "schema-id" : 0,
    "fields" : [ {
      "id" : 1,
      "name" : "order_id",
      "required" : false,
      "type" : "long"
    }, {
      "id" : 2,
      "name" : "customer_id",
      "required" : false,
      "type" : "long"
    }, {
      "id" : 3,
      "name" : "order_amount",
      "required" : false,
      "type" : "decimal(10, 2)"
    }, {
      "id" : 4,
      "name" : "order_ts",
      "required" : false,
      "type" : "timestamptz"
    } ]
  } ],
  "default-spec-id" : 0,
  "partition-specs" : [ {
    "spec-id" : 0,
    "fields" : [ {
      "name" : "order_ts_hour",
      "transform" : "hour",
      "source-id" : 4,
      "field-id" : 1000
    } ]
  } ],
  "last-partition-id" : 1000,
  "default-sort-order-id" : 0,
  "sort-orders" : [ {
    "order-id" : 0,
    "fields" : [ ]
  } ],
  "properties" : {
    "owner" : "irteam",
    "write.parquet.compression-codec" : "zstd"
  },
  "current-snapshot-id" : 8103580864574909489,
  "refs" : {
    "main" : {
      "snapshot-id" : 8103580864574909489,
      "type" : "branch"
    }
  },
  "snapshots" : [ {
    "sequence-number" : 1,
    "snapshot-id" : 8103580864574909489,
    "timestamp-ms" : 1736230211856,
    "summary" : {
      "operation" : "append",
      "spark.app.id" : "application_....._178749",
      "added-data-files" : "1",
      "added-records" : "1",
      "added-files-size" : "1277",
      "changed-partition-count" : "1",
      "total-records" : "1",
      "total-files-size" : "1277",
      "total-data-files" : "1",
      "total-delete-files" : "0",
      "total-position-deletes" : "0",
      "total-equality-deletes" : "0",
      "engine-version" : "3.5.3",
      "app-id" : "application_....._178749",
      "engine-name" : "spark",
      "iceberg-version" : "Apache Iceberg 1.7.1 (commit 4a432839233f2343a9eae8255532f911f06358ef)"
    },
    "manifest-list" : "/my/hdfs/path/for/iceberg/catalog/orders/metadata/snap-8103580864574909489-1-40e5fad9-a08d-4981-8ce8-57c5f0e58a1b.avro",
    "schema-id" : 0
  } ],
  "statistics" : [ ],
  "partition-statistics" : [ ],
  "snapshot-log" : [ {
    "timestamp-ms" : 1736230211856,
    "snapshot-id" : 8103580864574909489
  } ],
  "metadata-log" : [ {
    "timestamp-ms" : 1736229455394,
    "metadata-file" : "/my/hdfs/path/for/iceberg/catalog/orders/metadata/v1.metadata.json"
  } ]
}
```

</details>

`version-hint.text` 파일의 값이 `2`로 변경되었다.
즉, Iceberg 카탈로그가 2번째 스냅샷인 `v2.metadata.json` 메타데이터 파일을 가리키도록 갱신된 것이다.




### Merge Query




## Reading Queries in Apache Iceberg

### The SELECT Query

### The Time-Travel Query



## Conclusion
