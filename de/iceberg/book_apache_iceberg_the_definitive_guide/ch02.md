# Chapter 02. The Architecture of Apache Iceberg

Iceberg 테이블은 3개의 레이어로 구분된다. (카탈로그 레이어, 메타데이터 레이어, 데이터 레이어)

아래에서 부터 순서대로 살펴보자

![image](https://github.com/user-attachments/assets/602eea9b-f58f-417f-9382-c76e0b9a6a67)


## The Data Layer
- datafile들로 구성되어 실제 데이터가 저장되는 계층이다.
- delete file이 포함된다.
- 보통 데이터 레이어를 통해 사용자 질의 결과가 생성되지만 메타데이터 레이어에서 결과를 제공하기도 한다. (e.g. 칼럼 X의 최댓값을 구하는 질의)
- 보통 데이터레이어는 확장성과 비용감소의 이점을 위해 분산파일시스템(HDFS), 오브젝트 스토리지(Amazon S3, Azure Data Lake Storage;ADLS, Google Cloud Storage;GCS) 등에 저장된다.


### Datafile
- 데이터파일은 데이터 그 자체를 저장하는 파일이다.
- Parquet, ORC, Avro 등 다양한 파일포맷을 지원한다.
- 이 중 de facto standard는 Parquet이다. (칼럼 지향 구조로 인해 row-based file 대비 높은 OLAP 퍼포먼스 등)

<img width="764" alt="image" src="https://github.com/user-attachments/assets/d25896ee-9243-43f1-b1dc-adfe596c0e25" />

- [다른 구성도 이미지](https://blog.det.life/i-spent-8-hours-learning-parquet-heres-what-i-discovered-97add13fb28f)
- Parquet 파일의 구성
  - **Row Groups** : 데이터셋 row들의 부분집합. 여러 칼럼들로 구성된다.
  - **Column (Column Chunk)** : Row group을 구성하는 각각의 칼럼
  - **Page** : 칼럼의 값들이 저장되는 최소 저장단위. 동일 칼럼의 값들로만 구성되므로 압축에 유리하다.
- 쿼리 엔진, 도구가 이러한 저장구조의 단위들은 각각 따로 읽을 수 있어 병렬 읽기가 가능하다.
- Parquet는 통계치(최솟값, 최댓값 등)를 저장하므로 모든 파일들을 읽지 않고 효율적으로 data pruning할 수 있다. (Predicate Pushdown)


### Delete Files
- Delete file은 데이터셋에서 삭제된 레코드를 추적한다.
- data lake storage는 immutable하게 동작하므로 파일 내 실제 위치의 row를 업데이트할 수 없다.
- 따라서 새로운 파일을 작성하는 것으로 이를 해결한다.
  - 기존 파일의 복사본에 수정사항을 반영하여 새로운 파일을 만들거나 (copy-on-write; **COW**)
  - 기존 파일의 수정사항만 새로운 파일로 저장하고, 엔진이 읽을 때 병합하는 방식 (merge-on-read; **MOR**)
- Delete file은 Iceberg 테이블의 업데이트, 삭제를 수행하기 위한 MOR 전략에 사용된다.
- Delete file은 Iceberg v2 포맷에서만 지원한다.
<img width="704" alt="image" src="https://github.com/user-attachments/assets/21da6ab2-d12d-4c93-bfa9-71c51cbdd36d" />

- Delete file은 2가지 유형이 있다.
  - **positional delete file** : row를 데이터셋 내 위치로 식별한다.
  - **equality delete file** : row를 필드 값으로 식별한다.

#### Positional delete files
- 논리적으로 삭제된 row가 포함된 파일 경로와 파일 내 row의 위치 순번을 포함한다.
<img width="695" alt="image" src="https://github.com/user-attachments/assets/48ffe89a-61d0-42c8-82c2-0fdf469cc246" />

#### Equality delete files
- row를 필드의 값으로 식별하므로 primary key처럼 유니크하게 식별되는 칼럼으로 구분되는 경우에 사용하는 것이 가장 좋다.
- 하지만 한 버에 여러 개의 row가 삭제될 수 있다는 점에 유의해야 한다.
- positional delete file과 달리, 삭제할 row가 어디에 있는지에 대한 참조가 없다.
- 삭제 직후, 삭제 조건과 동일한 값을 가진 row가 새로 추가될 때 의도치 않게 삭제되지 않으려면?
  - Iceberg에선 manifest file이 각 상태의 datafile에 **sequence number**를 부여한다.
  - 이 번호 순서대로 작업이 이뤄지므로 삭제와 추가 작업이 의도대로 올바르게 동작할 수 있다. 
<img width="685" alt="image" src="https://github.com/user-attachments/assets/b436d68d-295c-4de4-96ac-17c85c5b4408" />


## The Metadata Layer
- Iceberg 테이블의 메타데이터 파일을 포함하는 필수적인 계층이다.
- manifest files, manifest lists, metadata files 3가지 타입의 파일로 구성된다.
- 메타데이터 레이어는 **time travel** , **schema evolution** 과 같은 핵심 기능을 위해 반드시 필요하다.

### Manifest Files
- Manifest 파일은 데이터 레이어의 **파일(datafiles, delete files) 수준에서 어떤 데이터가 어느 테이블에 있는지 추적**하는 파일이다.
  - 이는 Hive와 구별되는 Iceberg의 주된 특징이다.
- Manifest 파일은 datafile에 대해 아래와 같은 정보를 포함한다.
  - 파티션 멤버심 (partition membership)
  - 레코드 갯수 (record counts)
  - 칼럼 별 상한 및 하한 (lower and upper bounds) 등
- Manifest 파일에 통계값을 저장함으로써 얻는 이점
  - datafile에도 통계값이 이미 저장되어 있는 경우가 있다.
  - 하지만 Manifest 파일이 여러 datafile들에 대한 통계값을 저장함으로써, 통계값 질의 시 많은 수의 datafile들을 읽는 일을 크게 줄일 수 있다.
  - 실제로 단순히 footer만 읽더라도 읽어야 할 datafile 수가 많으면 소요시간도 길어질 수 밖에 없다.
- Hive 대비 통계값 생성 이점
  - Hive에선 전체 파티션 또는 전체 데이터를 읽고, 모든 데이터에 대한 통계값을 계산해야 하므로 비용이 크고 시간도 오래 걸린다.
  - Iceberg에선 하나 또는 여러 개의 datafile들을 처리하는 "작은 배치"마다 통계값이 작성되므로 비용이 작고 갱신도 자주 할 수 있다.
- manifest-file 예시
  - [Chapter_2/manifest-file.json](https://github.com/developer-advocacy-dremio/definitive-guide-to-apache-iceberg/blob/main/Resources/Chapter_2/manifest-file.json) (이해를 돕기 위해 json으로 작성했으나 실제로 Iceberg에서 manifest-file은 Avro 포맷으로 저장됨)

### Manifest Lists
- Manifest 리스트는 Iceberg 테이블의 특정 시점에 대한 스냅샷을 기록한 파일이다.
- 어느 시점의 테이블에 대한 아래 정보들을 기록한다.
  - 모든 Manifest 파일들의 목록과 위치, 파티션 정보, datafile 칼럼 파티션의 상항과 하한 값 등
- Manifest 리스트는 struct들의 배열이며, 각 struct는 하나의 Manifest 파일을 추적한다.
![image](https://github.com/user-attachments/assets/09b7b0f5-96c3-4d73-ab5b-1316b3fb7be7)
![image](https://github.com/user-attachments/assets/eceb2aed-840e-45b6-8ae0-207c2f6c5c35)

- manifest-list 예시
  - [Chapter_2/manifest- list.json](https://github.com/developer-advocacy-dremio/definitive-guide-to-apache-iceberg/blob/main/Resources/Chapter_2/manifest-list.json) (이해를 돕기 위해 json으로 작성했으나 실제로 Iceberg에서 manifest-file은 Avro 포맷으로 저장됨)

### Metadata Files
- Metadata 파일은 Menifest 리스트를 추적하는 파일이다.
- Iceberg 테이블의 특정 시점에 대한 메타데이터를 포함한다.
  - 테이블 스키마
  - 파티션 정보
  - 스냅샷 및 어느 스냅샷이 현재의 것인지에 대한 정보
- Iceberg 테이블이 변경될 때마다 새로운 Metadata 파일이 생성되고, 카탈로그를 통해 최신 버전으로 등록된다.
  - 이는 "동시 쓰기"와 같은 상황에서 테이블의 선형 기록이 정상적으로 동작하도록 보장한다.
  - (여러 곳에서 데이터를 동시에 쓰는 등의 동시 쓰기 시나리오)
  - 또한, 읽기 작업이 항상 테이블의 최신 버전을 보도록 보장한다.
<img width="699" alt="image" src="https://github.com/user-attachments/assets/1e7f5de7-459e-497b-8f3d-73b7ca600db1" />
<img width="699" alt="image" src="https://github.com/user-attachments/assets/38b1aaf4-1577-49c9-9455-3455b8196413" />

- metadata-file 예시
  - [Chapter_2/metadata-file.json](https://github.com/developer-advocacy-dremio/definitive-guide-to-apache-iceberg/blob/main/Resources/Chapter_2/metadata-file.json)

### Puffin Files
- 특정 쿼리의 성능을 높이기 위해 datafile이나 delete file 외에 또 다른 구조가 필요할 수도 있다.
  - 예시) 최근 30일간 유니크한 고객 수를 계산하려면 데이터 사이즈, 필드의 카디널리티, 할당된 리소스 등에 따라 오래 걸릴 수 있다.
- 퍼핀 파일은 예시처럼 범위가 긴 쿼리의 성능을 높이기 위한 통계값과 인덱스를 저장한 파일이다.
- 퍼핀 파일은 임의의 바이트열인 **blob** 과 이를 분석하기 위한 메타데이터를 포함한다.
- Apache DataSketches 라이브러리의 **Theta sketch** 유형만 지원한다.
  - 칼럼 값의 고유한 갯수에 대한 근사치(approximate number)를 훨씬 빠르고 적은 비용으로 계산할 수 있게 해준다.
  - 아래와 같은 케이스에서 특히 유용하다.
    - distinct values 계산이 필요한데 정확한 값을 구하기엔 비용이 너무 많이 들거나
    - 근사치를 허용하는 경우이거나
    - 대시보드와 같이 연산이 반복적으로 수행되는 경우
<img width="681" alt="image" src="https://github.com/user-attachments/assets/aac3ea1a-e571-4b6b-98c3-d9e263662efd" />


## The Catalog
- 테이블을 사용하려면 우선 현재 metadata 파일의 위치를 알아야 한다.
- 현재 metadata 포인터의 현재 위치를 찾을 수 있는 곳이 바로 **Iceberg catalog** 이다.
- Iceberg 카탈로그의 필수조건은 current metadata pointer를 업데이트하기 위한 **원자적 연산(atomic operations)** 을 지원해야 한다는 것이다.
  - 읽고 쓰는 모든 이가 주어진 시점에서 동일한 상태의 테이블을 볼 수 있도록 하기 위해서
- current metadata pointer
  - 카탈로그에는 각 테이블에 대해서 현재 metadata 파일을 가리키는 포인터(혹은 참조)가 존재한다.
  - current metadata pointer의 값은 metadata 파일의 위치이다.
  - 챕터 최상단 예시 이미지 참조
- 카탈로그의 유일한 요구사항은 current metadata pointer를 저장해야한다는 것과 원자성 보장 뿐이다.
- 이 덕분에 Iceberg 카탈로그에는 다양한 백엔드가 존재한다.
  - **Amazon S3를 카탈로그로 사용하는 경우**
    - 테이블의 메타데이터 폴더 하위의 `version-hint.text` 파일에 버전 번호, current metadata file를 저장한다.
    - 분산 파일시스템 및 유사한 시스템에 current metadata pointer를 저장하는 경우 hadoop 카탈로그라 부른다.
  - **Hive Metastore를 카탈로그로 사용하는 경우**
    - hive metastore의 `location` 이라는 테이블 속성에 current metadata file의 위치를 저장한다.
  - **Nessie를 카탈로그로 사용하는 경우**
    - Nessie의 `metadataLocation` 이라는 테이블 속성에 current metadata file의 위치를 저장한다.
  - 최신 문서 참고: https://iceberg.apache.org/concepts/catalog/#overview
- AWS Glue 카탈로그를 사용한 앞선 예시들에서 테이블의 메타데이터를 활용하기 위해 current metadata file을 확인하고자 한다면 아래와 같은 쿼리를 수행할 수 있다.
```sql
    SELECT *
    FROM my_catalog.iceberg_book.orders.metadata_log_entries
    ORDER BY timestamp DESC
    LIMIT 1
```
- 아래와 같이 `s3://jason-dremio-....`로 시작하는 metadata file의 경로를 확인할 수 있다.
<img width="626" alt="image" src="https://github.com/user-attachments/assets/2d7daee8-f724-4a2b-9c52-d8a1c08dfe62" />


